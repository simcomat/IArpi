{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7f7881",
   "metadata": {},
   "source": [
    "#  <font color=''>IA</font><font color='#7ac77a'>rpi</font> \n",
    "## Introduzindo Aprendizado de Máquina no ensino de Física\n",
    "--------------------------------------------\n",
    "\n",
    "Neste Jupyter Notebook são apresentados os passos para estudar um dataset de dados experimentais do rolamento em um plano inclinado. Concomitante ao uso de algoritmos de Aprendizado de Máquina (Machine Learning - ML), são realizados cálculos através de um modelo físico, discutido ao longo de cada tarefa.\n",
    "\n",
    "- 1) Carregando os dados;\n",
    "- 2) Realizando tarefa de Aprendizado Supervisionado de Classificação;\n",
    "- 3) Realizando tarefa de Aprendizado Supervisionado de Regressão.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214cca2f",
   "metadata": {},
   "source": [
    "### 1) Carregando os dados\n",
    "\n",
    "Para trabalhar com dados na forma de tabela, usamos a biblioteca **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Importando a biblioteca pandas com o nome pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados = pd.read_csv('../datasets/rolling.csv', sep=';') # Carrega o arquivo .csv na variável tabela_dados. \n",
    "#tabela_dados = pd.read_csv('https://raw.githubusercontent.com/simcomat/IArpi/main/datasets/rolling.csv', sep=';') # Para abrir o .csv direto do github" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados.head(5) # Visualizando as 5 primeiras linhas da tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce1856",
   "metadata": {},
   "source": [
    "Sabemos pela teoria que o coeficiente $\\beta$ é $\\frac{2}{5}$ para a esfera, $\\frac{1}{2}$ para o cilindro (disco) e $1$ para o aro.\n",
    "\n",
    "Vamos adicionar uma coluna na tabela contendo essa informação.\n",
    "\n",
    "Primeiro definimos uma função que recebe o nome do objeto e retorna o valor associado a ele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valor_beta(objeto):\n",
    "    betas = {\n",
    "        'esfera':0.4,\n",
    "        'cilindro':0.5,\n",
    "        'aro':1\n",
    "    }\n",
    "    return(betas[objeto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f07e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_beta('esfera')  # Testando a função que acabamos de criar (ela acessa a key objeto da estrutura dict betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192afe8",
   "metadata": {},
   "source": [
    "Vamos criar uma coluna 'Beta' na tabela que recebe a aplicação da função 'valor_beta' sobre a coluna 'Objeto':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4847e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados['Beta'] = tabela_dados['Objeto'].apply(valor_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf14968",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados.head(3) # Vendo o começo da tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72fd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados.tail(3) # Vendo a parte final da tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40709632",
   "metadata": {},
   "source": [
    "Vamos visualizar os dados plotando gráficos de dispersão. Abaixo estamos importando as bibliotecas Seaborn e Matplotlib para realizar essas funções. (O excesso de codificação está relacionado a formatação dos gráficos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c169ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos para plotar gráficos e ajustar formatação dos mesmos\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos tamanhos de fontes e ticks dos gráficos\n",
    "fsize = 12\n",
    "tsize = 10\n",
    "major = 5.0\n",
    "minor = 3.0\n",
    "\n",
    "style = 'default'\n",
    "plt.style.use(style)\n",
    "\n",
    "#plt.rcParams['text.usetex'] = True  # Para usar fonte tex (precisa instalar o tex antes)\n",
    "plt.rcParams['font.size'] = fsize      \n",
    "plt.rcParams['legend.fontsize'] = tsize\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['xtick.major.size'] = major\n",
    "plt.rcParams['xtick.minor.size'] = minor\n",
    "plt.rcParams['ytick.major.size'] = major\n",
    "plt.rcParams['ytick.minor.size'] = minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=3, sharex='col', sharey='row', figsize=(9, 5))\n",
    "plt.subplots_adjust(wspace=0.22, hspace=0.25)\n",
    "\n",
    "# Esfera\n",
    "esferas = tabela_dados[tabela_dados['Objeto']=='esfera']\n",
    "sns.scatterplot(data=esferas,\n",
    "              y=\"Tempo (s)\", x='Altura (m)',\n",
    "              hue = 'Ângulo (°)',palette=\"YlGn\", edgecolor='k', s=25, legend=False,\n",
    "              ax = axs[0][0],\n",
    "             )\n",
    "sns.scatterplot(data=esferas,\n",
    "              x=\"Altura (m)\", y='Velocidade Média (m/s)',\n",
    "              hue = 'Ângulo (°)',palette=\"YlGn\", edgecolor='k', s=25, legend=False,\n",
    "              ax = axs[1][0]\n",
    "             )\n",
    "\n",
    "# Cilindro\n",
    "cilindros = tabela_dados[tabela_dados['Objeto']=='cilindro']\n",
    "sns.scatterplot(data=cilindros,\n",
    "              y=\"Tempo (s)\", x='Altura (m)',\n",
    "              hue = 'Ângulo (°)', palette=\"YlGn\", edgecolor='k', s=25, legend=False,\n",
    "              ax = axs[0][1]\n",
    "             )\n",
    "sns.scatterplot(data=cilindros,\n",
    "              x=\"Altura (m)\", y='Velocidade Média (m/s)',\n",
    "              hue = 'Ângulo (°)',palette=\"YlGn\", edgecolor='k', s=25, legend=False,\n",
    "              ax = axs[1][1]\n",
    "             )\n",
    "\n",
    "# Aro\n",
    "aros = tabela_dados[tabela_dados['Objeto']=='aro']\n",
    "sns.scatterplot(data=aros,\n",
    "              y=\"Tempo (s)\", x='Altura (m)',\n",
    "              hue = 'Ângulo (°)', palette=\"YlGn\", edgecolor='k', s=25, legend=False,\n",
    "              ax = axs[0][2]\n",
    "             )\n",
    "sns.scatterplot(data=aros,\n",
    "              x=\"Altura (m)\", y='Velocidade Média (m/s)',\n",
    "              hue = 'Ângulo (°)',palette=\"YlGn\", edgecolor='k', s=25, legend=True,\n",
    "              ax = axs[1][2]\n",
    "             )\n",
    "\n",
    "# Adicionando Legenda\n",
    "plt.legend(edgecolor = 'w', title='Ângulos (°)',bbox_to_anchor=(1.05, 1.5), loc='upper left', borderaxespad=0)\n",
    "leg = axs[1][2].get_legend()\n",
    "\n",
    "for lbl in leg.get_texts():\n",
    "    label_text = lbl.get_text()\n",
    "    new_text = f'{float(label_text):,.1f}'\n",
    "    lbl.set_text(new_text)\n",
    "    \n",
    "for ha in leg.legendHandles:\n",
    "    ha.set_edgecolor(\"k\")\n",
    "    \n",
    "# Arrumando cada subplot do gráfico\n",
    "lables_subplots=[['(a)','(b)','(c)'],['(d)','(e)','(f)']]\n",
    "for i in range(0,2):\n",
    "    for j in range(0,3):\n",
    "        axs[i][j].grid(alpha=0.2, linestyle='-.', color='k', linewidth =1)\n",
    "        trans = mtransforms.ScaledTranslation(10/72, -5/72, fig.dpi_scale_trans)\n",
    "        axs[i][j].text(0.0, 1.0, lables_subplots[i][j], transform=axs[i][j].transAxes + trans,\n",
    "                fontsize='medium', verticalalignment='top')\n",
    "        axs[i][j].set_xlim([0,0.15])\n",
    "\n",
    "        if i==0:\n",
    "            axs[i][j].set_ylim([0,2.5])\n",
    "            axs[i][j].set_yticks([0, 0.5, 1, 1.5, 2, 2.5])\n",
    "            if j==0:  axs[i][j].set_title('Esfera')\n",
    "            if j==1:  axs[i][j].set_title('Cilindro')\n",
    "            if j==2:  axs[i][j].set_title('Aro')\n",
    "        else:\n",
    "            axs[i][j].set_ylim([0,1])\n",
    "            axs[i][j].set_yticks([0, 0.5, 1])\n",
    "\n",
    "        axs[i][j].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        axs[i][j].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "#plt.savefig(\"dados.pdf\", format=\"pdf\", bbox_inches='tight') # Para salvar a imagem em formato .pdf (.png, .jpeg, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5877f12",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "## 2) Classificação\n",
    "\n",
    "Nesta tarefa queremos classificar cada objeto a partir dos dados experimentais.\n",
    "\n",
    "Primeiramente vamos rodar o modelo físico simplifcado sobre os dados. \n",
    "\n",
    "Iremos fazer o cálculo pontual do valor de $\\beta$ para cada dado experimental, seguindo:\n",
    "\n",
    "### $\\beta = \\frac{0.5gh}{V_{med}^2}-1$\n",
    "\n",
    "Vamos definir uma função para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Para funcoes matematicas de seno/cosseno e conversao radiano/grau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27bcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A função recebe a altura, tempo e o ângulo de inclinação e devolve beta predito\n",
    "def encontra_beta(altura, tempo, theta):\n",
    "    g=9.8                                        # Aceleração da gravidade\n",
    "    distancia=altura/np.sin(np.deg2rad(theta))   # Distância percorrida sobre o plano\n",
    "    vmed = distancia/tempo                       # Velocidade média do objeto\n",
    "    beta = (0.5*g*altura/vmed**2)-1\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01802647",
   "metadata": {},
   "source": [
    "Aplicando a função na tabela de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados['Beta MF'] = tabela_dados.apply(lambda x: encontra_beta(x['Altura (m)'],\n",
    "                                                                     x['Tempo (s)'],\n",
    "                                                                     x['Ângulo (°)']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b6308",
   "metadata": {},
   "source": [
    "Agora vamos aplicar o modelo a Aprendizado de Máquina de Classificação.\n",
    "\n",
    "Precisamos separar as colunas pertinentes do modelo (features) das outras colunas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tabela_dados[['Altura (m)','Ângulo (°)', 'Tempo (s)']]  # Features\n",
    "y = tabela_dados['Objeto']                                  # Atributo alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f07cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3597027",
   "metadata": {},
   "source": [
    "Agora vamos separar as linhas em dois conjuntos, um de **treinamento** e outro de **teste**. Vamos usar a biblioteca Scikit-Learn para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e55fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo conjunto de treinamento e conjunto de teste\n",
    "# Stratify garante que a quantidade de cada objeto seja aproximadamente o mesmo nos conjuntos de treino e teste\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train), len(y_train), len(x_test), len(y_test) # Vendo a quantidade de linhas em cada conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa9c18",
   "metadata": {},
   "source": [
    "Alguns métodos de Aprenizado de Máquina tendem a dar mais importância para features com valores numéricos maiores. Como os modelos não conhecem \"unidade físicas\", vamos transformar os dados numéricos de entrada (x) através de um escalonador. A ideia é que o intervalo de valores fique entre 0 e 1 para cada feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler   # Escalonador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()   # Instanciando o escalonador\n",
    "scaler.fit(x_train)       # Treinando o escalonador apenas com os dados de treinamento\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)   # Transformando os dados de treinamento pelo escalonador treinado\n",
    "x_test_scaled = scaler.transform(x_test)     # Transformando os dados de teste pelo escalonado treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e249b0",
   "metadata": {},
   "source": [
    "Uma vez que os dados estão devidamente transformados para os algoritmos de Aprendizado de Máquina, vamos importar eles do Sklearn e instanciá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier           # Modelo base\n",
    "from sklearn.neighbors import KNeighborsClassifier  # k-vizinhos mais próximos (KNN)\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # GradientBoosting\n",
    "from sklearn.svm import SVC                         # Maquina de Vetor Suporte SVM\n",
    "from sklearn.neural_network import MLPClassifier    # Multlayer Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB          # Naive Bayes\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d841004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "base_model = DummyClassifier(strategy=\"uniform\")\n",
    "base_model.fit(x_train_scaled,y_train)\n",
    "\n",
    "# LDA (Discriminante Linear)\n",
    "lda = LinearDiscriminantAnalysis()  # Criando classificador (sem nenhum hiperparametro)\n",
    "lda.fit(x_train_scaled, y_train)    # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# QDA (Discriminante Quadrático)\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(x_train_scaled, y_train)\n",
    "\n",
    "# GaussianNB\n",
    "gNB = GaussianNB()\n",
    "gNB.fit(x_train_scaled, y_train)\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()     # Criando classificador (sem nenhum hiperparametro)\n",
    "knn.fit(x_train_scaled, y_train) # Treinamos o classificador passando apenas o conjunto de dados de treinamento \n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "svm.fit(x_train_scaled, y_train)\n",
    "\n",
    "# MLP \n",
    "mlpc = MLPClassifier(random_state=42)\n",
    "mlpc.fit(x_train_scaled, y_train)\n",
    "# (As iterações de aprendizado podem alcançar o limite default emitindo um warning) \n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestClassifier(random_state=42) # Criando classificador (hiperparametro de seed)\n",
    "rf.fit(x_train_scaled, y_train) #  \n",
    "\n",
    "#Gradient Boosting\n",
    "gboo = GradientBoostingClassifier(random_state=42)\n",
    "gboo.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84edcec1",
   "metadata": {},
   "source": [
    "Vamos criar um discionário contendo todos os objetos dos classificadores treinados. Dessa forma, poderemos acessar qualquer um dos modelos através da variável ``` classificacores```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificadores = {\n",
    "    'BM':base_model,\n",
    "    'LDA':lda,\n",
    "    'QDA':qda,\n",
    "    'GNB':gNB,\n",
    "    'KNN':knn,\n",
    "    'SVM':svm,\n",
    "    'RF':rf,\n",
    "    'GB':gboo,\n",
    "    'MLP':mlpc\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c7ec6",
   "metadata": {},
   "source": [
    "Pronto! Nossos algoritmos de Aprendizado de Máquina foram treinandos para realizar a classificação dos dados. Eles já estão prontos para uso! Contudo, precisamos ver qual o desempenho dele para a tarefa pretendida. Para isso, vamos verificar se eles acertam as classificações dos objetos sobre o conjunto de teste.\n",
    "\n",
    "Vamos medir algumas métricas em relação a isso: acurácia e o coeficiente kappa de Cohen. Existem outras métricas possíveis, entretanto focaremos nessas. Primeiro vamos importá-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, make_scorer  # Métricas de  Classificacao\n",
    "from sklearn.metrics import confusion_matrix                                # Métricas de Classificacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d1ee9",
   "metadata": {},
   "source": [
    "Agora vamos criar variáveis (estruturas dicionário e lista) para armazenar o valor de cada métrica calculada para cada modelo testado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados={}\n",
    "resultados_kappa={}\n",
    "resultados_accuracia={}\n",
    "\n",
    "lab = ['esfera','cilindro','aro']\n",
    "for clf_name, clf in classificadores.items():  # Iterando sobre todos os modelos treinados\n",
    "    y_pred = clf.predict(x_test_scaled)        # Passando para o ML apenas os dados de teste escalonados\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    kappa =  cohen_kappa_score(y_test, y_pred, labels=lab)\n",
    "    \n",
    "    scoring = {'accuracy': acc,\n",
    "               'kappa' :kappa,\n",
    "         }\n",
    "    resultados_kappa[clf_name]=kappa\n",
    "    resultados_accuracia[clf_name]=acc\n",
    "    resultados[clf_name]=scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa3075",
   "metadata": {},
   "source": [
    "Vamos usar uma estrutura de dados pandas DataFrame para visualizar os dados das métricas que armazenamos no passo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_teste_classificao = pd.DataFrame(data=resultados)\n",
    "resultado_teste_classificao.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8289db",
   "metadata": {},
   "source": [
    "Como o algoritmo KNN rendeu o melhor resultado, vamos criar a Matriz de Confusão dele e compará-lo com o modelo físico (MF) calculado anteriormente.\n",
    "\n",
    "Para facilitar a comparação, vamos criar uma imagem adequada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f68177",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= knn.predict(x_test_scaled)                # Resultados apenas do KNN\n",
    "matriz_confusao=confusion_matrix(y_test, y_pred)  # Matriz de confusão do KNN\n",
    "result_test=tabela_dados.iloc[x_test.index]       # Pegando apenas as linhas de teste da tabela original (para ver o MF)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura Classificação\n",
    "fig, axd = plt.subplot_mosaic([['(a)', '(c)', '(d)'],\n",
    "                               ['(b)', '(c)', '(d)']],\n",
    "                              figsize=(11, 4.5), constrained_layout=True)\n",
    "\n",
    "# Gráficos de barras de comparação dos métodos\n",
    "sns.barplot(x=list(resultados_accuracia.keys()),y =[round(resultados_accuracia[k],3) for k in resultados_accuracia.keys()],\n",
    "            ax=axd['(a)'], color='#81BC82', edgecolor='grey' )\n",
    "sns.barplot(x=list(resultados_kappa.keys()), y =[round(resultados_kappa[k],3) for k in resultados_kappa.keys()],\n",
    "            ax=axd['(b)'], color='#81BC82', edgecolor='grey' )\n",
    "\n",
    "axd['(b)'].set_xlabel('Algoritmos de Classificação')\n",
    "axd['(a)'].set_ylabel('Acurácia'), axd['(a)'].set_ylim([0,1])\n",
    "axd['(b)'].set_ylabel('$\\kappa$ de Cohen'), axd['(b)'].set_ylim([0,1])\n",
    "axd['(a)'].set_yticks([0, 0.5, 1])\n",
    "axd['(b)'].set_yticks([0, 0.5, 1])\n",
    "axd['(a)'].bar_label(axd['(a)'].containers[0], rotation=90, label_type='center', color='white')\n",
    "axd['(a)'].set_title('Métricas')\n",
    "\n",
    "pos=0.05\n",
    "colors_kappa=['k','k','k','k','w','k','w','w','k']\n",
    "y_pos_kappa=[0.4,0.47,0.56,0.52,0.5,0.58,0.5,0.5,0.68]\n",
    "for i, kp in enumerate([round(resultados_kappa[k],3) for k in resultados_kappa.keys()]):       \n",
    "    plt.text(pos,y_pos_kappa[i],\n",
    "             s =  '{0:.3f}'.format(kp),\n",
    "             color=colors_kappa[i],\n",
    "             rotation=90,\n",
    "             horizontalalignment='center',\n",
    "             verticalalignment='top',\n",
    "             multialignment='center')\n",
    "    pos = pos+1\n",
    "\n",
    "plt.setp(axd['(a)'].get_xticklabels(), visible=False)\n",
    "axd['(b)'].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Matriz de Confusao\n",
    "sns.heatmap(matriz_confusao, annot=True, ax=axd['(c)'], cmap=\"YlGn\",\n",
    "            xticklabels=['esfera', 'cilindro', 'aro'], yticklabels=['esfera', 'cilindro', 'aro'],\n",
    "            cbar_kws={'label': 'Quantidade de Exemplos Testados'},\n",
    "            robust=True)\n",
    "axd['(c)'].set_ylabel('Objeto Verdadeiro')\n",
    "axd['(c)'].set_xlabel('Objeto Predito')\n",
    "axd['(c)'].set_title('Aprendizado de Máquina')\n",
    "\n",
    "  \n",
    "# Violinplot\n",
    "sns.violinplot(y='Objeto',x='Beta MF', data=result_test, order =['esfera', 'cilindro', 'aro'],\n",
    "               palette=\"YlGn\", ax=axd['(d)'])\n",
    "axd['(d)'].get_yaxis().set_visible(False)\n",
    "plt.setp(axd['(d)'].get_yticklabels(), visible=False)\n",
    "axd['(d)'].set_xlabel('$\\\\beta$ predito'), axd['(d)'].set_xlim([-0.5,2])\n",
    "axd['(d)'].set_title('Modelo Físico')\n",
    "axd['(d)'].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "axd['(d)'].set_ylim([2.5,-0.5])\n",
    "axd['(d)'].plot([0.4,0.4], [-1,3], color='#d5e6ac', linestyle='dashed', linewidth = 1) \n",
    "axd['(d)'].plot([0.5,0.5], [-1,3], color='#81bc82', linestyle='dashed', linewidth = 1) \n",
    "axd['(d)'].plot([1,1], [-1,3], color='#2e7748', linestyle='dashed', linewidth = 1) \n",
    "custom_lines = [Line2D([0], [0], color='#d5e6ac', lw=5),\n",
    "                Line2D([0], [0], color='#81bc82', lw=5),\n",
    "                Line2D([0], [0], color='#2e7748', lw=5)]\n",
    "axd['(d)'].legend(handles=custom_lines, labels=['esfera', 'cilindro', 'aro'],\n",
    "                  title='Objeto Verdadeiro',loc='upper right', frameon=False)\n",
    "\n",
    "# Escrevendo os itens (a), (b), ... em cada um dos gráficos da figura\n",
    "for label, ax in axd.items():\n",
    "    if label=='(c)':\n",
    "        trans = mtransforms.ScaledTranslation(-20/72, 7/72, fig.dpi_scale_trans)\n",
    "        ax.text(0.0, 1.0, label, transform=ax.transAxes + trans,\n",
    "                fontsize='medium', verticalalignment='top')\n",
    "    else:\n",
    "        trans = mtransforms.ScaledTranslation(10/72, -5/72, fig.dpi_scale_trans)\n",
    "        ax.text(0.0, 1.0, label, transform=ax.transAxes + trans,\n",
    "                fontsize='medium', verticalalignment='top')\n",
    "\n",
    "#plt.savefig(\"classificacao.pdf\", format=\"pdf\") # Para salvar a imagem em formato pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b048fc2",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "## 3) Regressão\n",
    "\n",
    "Nesta tarefa queremos predizer a Velocidade Média a partir dos dados experimentais.\n",
    "\n",
    "Queremos manter a mesma informação para o Modelo Físico (MF) e os modelos de Aprendizado de Máquina (ML). Como no modelo físico entramos com $\\beta$ de cada objeto, queremos fazer o mesmo com o modelo de ML, entretanto devemos lembrar que estamos presos as medidas feitas. Não medimos $\\beta$ experimentalmente, dessa forma não seria justo inseri-lo diretamente na tabela para os modelos de ML, afinal eles devem ser agnósticos a física. Para contornar essa complicação, e ainda assim indicar para o ML que são objetos diferentes, podemos passar a coluna de observação \"Objeto\" diretamente.\n",
    "\n",
    "Entretanto, os algoritmos de regressão não estão preparados para receber um nome (string) como entrada. Então, apenas fornecer o nome do objeto (esfera, cilindro, aro) para o modelo não irá funcionar. Precisamos primeiro converter esses nomes em uma representação numérica. Para isso vamos usar o OneHot Encoding. Nessa representação, cada valor do atributo objeto torna-se uma característica única (feature). Para 3 valores de objetos teremos 3 novas colunas com valores binários (verdadeiro ou falso, 1 ou 0) representando cada objeto, por exemplo, se seguirmos (esfera, cilindro, aro) uma esfera será represntada pela tupla (1,0,0) enquanto um aro será por (0,0,1). Fisicamente, misturas não seriam possiveis como uma esfera-aro (1,0,1), mas em outras situações essa técnica pode ser usada para representar a presença de mais um objeto (como palavras em uma frase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572cfc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pd.get_dummies(tabela_dados.Objeto, prefix='objeto') # One hot encoding\n",
    "tabela_dados = tabela_dados.join(ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e608956",
   "metadata": {},
   "source": [
    "Agora vamos rodar o modelo físico simplifcado sobre os dados. \n",
    "\n",
    "Iremos fazer o cálculo pontual do valor de $v_{med}$ para cada dado experimental, seguindo:\n",
    "\n",
    "### $v_{med}=\\frac{1}{2}\\sqrt{\\frac{2gh}{1+\\beta}}$\n",
    "\n",
    "\n",
    "Vamos definir uma função para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontra_velocidade(altura, objeto0, objeto1, objeto2):\n",
    "    g=9.8 \n",
    "    # O MF sabe o beta devido a teoria\n",
    "    if objeto0==1:\n",
    "        beta=2/5 # Esfera\n",
    "    elif objeto1==1:\n",
    "        beta=1/2 # Cilindro\n",
    "    elif objeto2==1:\n",
    "        beta=1 # Aro\n",
    "    vel_med = (0.5)*(2*g*altura/(1+beta))**0.5\n",
    "    return vel_med"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c782d",
   "metadata": {},
   "source": [
    "Para aplicar o ML, vamos separar os dados e escalonar as features de entrada, igual fizemos para classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tabela_dados[['Altura (m)','Ângulo (°)', 'objeto_aro', 'objeto_cilindro','objeto_esfera']] \n",
    "y = tabela_dados['Velocidade Média (m/s)'] # Atributo alvo\n",
    "\n",
    "# Dividindo conjunto de treinamento e conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc5a59",
   "metadata": {},
   "source": [
    "De maneira análoga a classificação, vamos importar os algoritmos de Regressão e instanciar eles no código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ff13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression      # Regressao Linear\n",
    "from sklearn.svm import SVR                            # Regressão por Máquina de Vetor Suporte\n",
    "from sklearn.tree import DecisionTreeRegressor         # Regressão por Árvore de Decisão\n",
    "from sklearn.neighbors import KNeighborsRegressor      # k-vizinhos mais próximos (KNN)\n",
    "from sklearn.ensemble import RandomForestRegressor     # RandomForest\n",
    "from sklearn.ensemble import GradientBoostingRegressor # GradientBoosting\n",
    "from sklearn.neural_network import MLPRegressor        # Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressao Linear\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train_scaled,y_train)\n",
    "\n",
    "# KNN Regressor\n",
    "knnr = KNeighborsRegressor()\n",
    "knnr.fit(x_train_scaled,y_train)\n",
    "\n",
    "# SVM\n",
    "svmr = SVR()\n",
    "svmr.fit(x_train_scaled,y_train)\n",
    "\n",
    "# Regressão por Árvore de Decisão\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(x_train_scaled,y_train)\n",
    "\n",
    "# Regressão por Random\n",
    "rfr = RandomForestRegressor(random_state=42)\n",
    "rfr.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Regressõ por GB\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "gbr.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Multilayer Perceptron\n",
    "mlpr =  MLPRegressor(random_state=42)\n",
    "mlpr.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressores = {\n",
    "    'LR':lr,\n",
    "    'KNNR':knnr,\n",
    "    'SVMR':svmr,\n",
    "    'RFR':rfr,\n",
    "    'GBR':gbr,\n",
    "    'MLPR':mlpr,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d38604",
   "metadata": {},
   "source": [
    "Assim como na classificação, vamos importar as bibliotecas de métricas e calcular o desempenho dos algoritmos sobre os dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score       # Métricas de Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados={}\n",
    "resultados_MAE={}\n",
    "resultados_R2={}\n",
    "\n",
    "for rg_name, rg in regressores.items():\n",
    "    \n",
    "    y_pred = rg.predict(x_test_scaled)        # Entrando os dados de teste no modelo ML\n",
    "    mae = mean_absolute_error(y_test, y_pred) # Calculando métrica MAE\n",
    "    r2 = r2_score(y_test, y_pred)             # Calculando métrica R2\n",
    "    \n",
    "    # Salvando resultados\n",
    "    scoring = {'MAE': mae,\n",
    "               'R2' :r2\n",
    "         }\n",
    "    resultados[rg_name]=scoring\n",
    "    resultados_MAE[rg_name]=mae\n",
    "    resultados_R2[rg_name]=r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed94522",
   "metadata": {},
   "source": [
    "Fazendo as predições de velocidade pelo modelo físico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2 = x_test.copy() \n",
    "x_test2['Vel MF'] = x_test2.apply(lambda x: encontra_velocidade(x['Altura (m)'], x['objeto_aro'],\n",
    "                                                            x['objeto_cilindro'], x['objeto_esfera']), axis=1)\n",
    "y_pred_modelo = np.array(x_test2['Vel MF'])\n",
    "\n",
    "resultados_MAE['MF'] = mean_absolute_error(y_test, y_pred_modelo)\n",
    "resultados_R2['MF'] = r2_score(y_test, y_pred_modelo)\n",
    "resultados['MF'] = {'MAE': resultados_MAE['MF'],\n",
    "                    'R2' :resultados_R2['MF']\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa96da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_teste_regressao = pd.DataFrame(data=resultados)\n",
    "resultado_teste_regressao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= knnr.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548edb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura Regressor\n",
    "fig, axd = plt.subplot_mosaic([['(a)', '(c)', '(d)'],\n",
    "                               ['(b)', '(c)', '(d)']],\n",
    "                              figsize=(11, 4.5), constrained_layout=True)\n",
    "\n",
    "\n",
    "# Gráficos de barras (a) e (b)\n",
    "clrs = ['#81BC82' for i in regressores]+['#d5e6ac'] # Definição de cores em código hexadecimal\n",
    "sns.barplot(x=list(resultados_MAE.keys()), y =[round(resultados_MAE[k],3) for k in resultados_MAE.keys()],\n",
    "            ax=axd['(a)'], palette=clrs, edgecolor='grey')\n",
    "sns.barplot(x=list(resultados_R2.keys()),  y =[round(resultados_R2[k],3) for k in resultados_R2.keys()],\n",
    "            ax=axd['(b)'], palette=clrs, edgecolor='grey')\n",
    "\n",
    "axd['(b)'].set_xlabel('Algoritmos de Regressão')\n",
    "axd['(a)'].set_ylabel('MAE (m/s)'), axd['(a)'].set_ylim([0,0.06])\n",
    "axd['(b)'].set_ylabel('$R^2$'), axd['(b)'].set_ylim([0,1])\n",
    "axd['(a)'].set_yticks([0, 0.03, 0.06])\n",
    "axd['(b)'].set_yticks([0, 0.5, 1])\n",
    "axd['(b)'].bar_label(axd['(b)'].containers[0],  rotation=90, label_type='center', color='white')\n",
    "axd['(a)'].set_title('Métricas')\n",
    "plt.setp(axd['(a)'].get_xticklabels(), visible=False)\n",
    "axd['(b)'].tick_params(axis='x', rotation=45)\n",
    "\n",
    "pos=0.05\n",
    "colors_mae=['w','k','w','k','k','w','w']  # Cores dos valores expressos nas barras do item (a)\n",
    "y_pos_mae=[0.027,0.038,0.033,0.038,0.038,0.027,0.04] # Altura dos valores expressos nas abrras do item (a)\n",
    "for i, kp in enumerate([round(resultados_MAE[k],3) for k in resultados_MAE.keys()]):       \n",
    "    axd['(a)'].text(pos,y_pos_mae[i],\n",
    "             s =  '{0:.3f}'.format(kp),\n",
    "             color=colors_mae[i],\n",
    "             rotation=90,\n",
    "             horizontalalignment='center',\n",
    "             verticalalignment='top',\n",
    "             multialignment='center')\n",
    "    pos = pos+1\n",
    "\n",
    "\n",
    "# Grafico de dispersão ML\n",
    "sns.scatterplot(x=y_test,y=y_pred, label='$y_{pred}$', color='#81BC82', edgecolor='k',\n",
    "                marker='o', s=25, ax=axd['(c)'])\n",
    "axd['(c)'].plot([0,1], [0,1], color='r', linestyle='dashed', linewidth = 1,\n",
    "                  label='$y_{pred}=y_{test}$') # Reta 100% correto\n",
    "axd['(c)'].set(xlabel='Velocidade Média \\n Experimental (m/s)', ylabel='Velocidade Média Predita (m/s)')\n",
    "axd['(c)'].legend(loc=4)\n",
    "axd['(c)'].set_xlim([0.2,0.8]), axd['(c)'].set_ylim([0.2,0.8])\n",
    "axd['(c)'].set_xticks([0.2, 0.4, 0.6, 0.8]), axd['(c)'].set_yticks([0.2, 0.4, 0.6, 0.8])\n",
    "axd['(c)'].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "axd['(c)'].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "axd['(c)'].grid(alpha=0.2, linestyle='-.', color='k', linewidth =1)\n",
    "axd['(c)'].set_title('Aprendizado de Máquina')\n",
    "\n",
    "# Grafico de dispersão MF\n",
    "sns.scatterplot(x=y_test,y=y_pred_modelo, label='$y_{pred}$', color='#d5e6ac', edgecolor='k',\n",
    "                marker='o', s=25, ax=axd['(d)'])\n",
    "axd['(d)'].plot([0,1], [0,1], color='r', linestyle='dashed', linewidth = 1,\n",
    "                  label='$y_{pred}=y_{test}$') # Reta 100% correto\n",
    "axd['(d)'].set(xlabel='Velocidade Média \\n Experimental (m/s)', ylabel='Velocidade Média Predita (m/s)')\n",
    "axd['(d)'].legend(loc=4)\n",
    "axd['(d)'].set_xlim([0.2,0.8]), axd['(d)'].set_ylim([0.2,0.8])\n",
    "axd['(d)'].set_xticks([0.2, 0.4, 0.6, 0.8]), axd['(d)'].set_yticks([0.2, 0.4, 0.6, 0.8])\n",
    "axd['(d)'].xaxis.set_minor_locator(AutoMinorLocator())\n",
    "axd['(d)'].yaxis.set_minor_locator(AutoMinorLocator())\n",
    "axd['(d)'].grid(alpha=0.2, linestyle='-.', color='k', linewidth =1)\n",
    "axd['(d)'].set_title('Modelo Físico')\n",
    "axd['(d)'].yaxis.tick_right()\n",
    "axd['(d)'].set_ylabel('')\n",
    "\n",
    "# Escrevendo os itens (a), (b), ... em cada um dos gráficos da figura\n",
    "for label, ax in axd.items():\n",
    "    trans = mtransforms.ScaledTranslation(10/72, -5/72, fig.dpi_scale_trans)\n",
    "    ax.text(0.0, 1.0, label, transform=ax.transAxes + trans,\n",
    "            fontsize='medium', verticalalignment='top')\n",
    "    \n",
    "#plt.savefig(\"regressao.pdf\", format=\"pdf\") # Para salvar a imagem em formato pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
